{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLP를 이용한 MNIST Dataset 학습 및 테스트 실습\n",
    "\n",
    "MNIST 데이터는 0부터 9까지의 숫자를 손글씨로 적은 이미지와 그에 대한 레이블 쌍으로 이루어진 총 7만개의 데이터셋입니다.  \n",
    "\n",
    "이번 실습에서는 간단한 Multi-Layer Perceptron을 이용하여 MNIST 데이터셋을 학습시키고 훈련된 모델을 이용하여 0~9까지의 숫자를 Classification하는 실습을 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 라이브러리 임포트\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**MNIST 데이터를 로드하고 시각화해보기 위해 필요한 라이브러리들을 임포트합니다.**  \n",
    "다운로드하는데 시간이 조금 걸릴 수 있습니다.  \n",
    "한 번에 더 많은 데이터를 로드하려는 경우 batch_size를 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터로드에 사용할 서브 프로세스 수\n",
    "num_workers = 0\n",
    "# 배치당 로드할 샘플 수\n",
    "batch_size = 20\n",
    "\n",
    "# 데이터를 Float Tensor형으로 변환합니다.\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# 학습 및 테스트 데이터 로드\n",
    "train_data = dsets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = dsets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 학습 및 테스트 데이터 로더 준비\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다운로드한 MNIST 데이터셋을 한번 시각화 시켜봅시다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST 데이터를 좀더 세분화하여 시각화 해봅니다.**  \n",
    "이미지 한장을 불러와 각 픽셀마다의 값을 백분율로 출력합니다.\n",
    "각 픽셀당 RGB값이 255에 가까워질수록 1에 가까운 값을 가집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.squeeze(images[1])\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "width, height = img.shape\n",
    "thresh = img.max()/2.5\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "        ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**간단한 Multi-layer Perceptron 설계하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## 신경망 구조 정의하기\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512) #첫번째 Layer\n",
    "        self.fc2 = nn.Linear(512, 512) #두번째 Layer\n",
    "        self.fc3 = nn.Linear(512, 10) #세번째 Layer\n",
    "        self.dropout = nn.Dropout(0.2) #드롭아웃 Layer\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss 함수 및 Optimizer 지정하기**\n",
    "Loss 함수는 CrossEntropyLoss를 사용하고, Optimizer는 SGD를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP 학습하기**  \n",
    "위에서 설계한 MLP를 학습시켜 봅시다.\n",
    "그래프를 통하여 Loss의 변화를 파악 하여 학습이 올바르게 이루어지고 있는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "n_epochs = 20 # 학습 epoch 지정\n",
    "liveloss = PlotLosses()\n",
    "model.train() \n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    logs = {}\n",
    "    train_loss = 0.0\n",
    "    ###################\n",
    "    #    모델 학습    #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # 모든 optimizer 변수와 gradients를 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 정방향 학습 : 입력을 모델로 전달하여 예측된 출력 계산\n",
    "        output = model(data)\n",
    "        # Loss 계산\n",
    "        loss = criterion(output, target)\n",
    "        # 역전파 : 모델의 매개변수를 고려하여 loss의 gradients를 계산\n",
    "        loss.backward()\n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        # 훈련 Loss 업데이트\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        visualize_loss = train_loss/len(train_loader.dataset)\n",
    "        logs['train_loss'] = visualize_loss\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        visualize_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련된 모델 테스트 해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트 결과를 시각화 하기**\n",
    "각 숫자당 모델이 예측한 값과 실제 값을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "output = model(images)\n",
    "_, preds = torch.max(output, 1)\n",
    "images = images.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
