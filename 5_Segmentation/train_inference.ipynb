{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Segmentation - U-Net을 이용한 Shoe Dataset 학습 실습\n",
    "  \n",
    "  \n",
    "이번 시간에는 U-Net을 이용하여 Shoe Dataset을 학습시키고, Segmentation 해보는 실습을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from model import UNet\n",
    "from loss_func import BCELoss2d, dice_coeff\n",
    "from data_utils import ImageDataset, TestImageDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Instructor:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        if opt.inference:\n",
    "            self.testset = TestImageDataset(fdir=opt.impaths['test'], imsize=opt.imsize)\n",
    "        else:\n",
    "            self.trainset = ImageDataset(fdir=opt.impaths['train'], bdir=opt.impaths['btrain'], imsize=opt.imsize, mode='train', aug_prob=opt.aug_prob, prefetch=opt.prefetch)\n",
    "            self.valset = ImageDataset(fdir=opt.impaths['val'], bdir=opt.impaths['bval'], imsize=opt.imsize, mode='val', aug_prob=opt.aug_prob, prefetch=opt.prefetch)\n",
    "        self.model = UNet(n_channels=3, n_classes=1, bilinear=self.opt.use_bilinear)\n",
    "        if opt.checkpoint:\n",
    "            self.model.load_state_dict(torch.load('./state_dict/{:s}'.format(opt.checkpoint), map_location=self.opt.device))\n",
    "            print('checkpoint {:s} has been loaded'.format(opt.checkpoint))\n",
    "        if opt.multi_gpu == 'on':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model = self.model.to(opt.device)\n",
    "        self._print_args()\n",
    "    \n",
    "    def _print_args(self):\n",
    "        n_trainable_params, n_nontrainable_params = 0, 0\n",
    "        for p in self.model.parameters():\n",
    "            n_params = torch.prod(torch.tensor(p.shape))\n",
    "            if p.requires_grad:\n",
    "                n_trainable_params += n_params\n",
    "            else:\n",
    "                n_nontrainable_params += n_params\n",
    "        self.info = 'n_trainable_params: {0}, n_nontrainable_params: {1}\\n'.format(n_trainable_params, n_nontrainable_params)\n",
    "        self.info += 'training arguments:\\n' + '\\n'.join(['>>> {0}: {1}'.format(arg, getattr(self.opt, arg)) for arg in vars(self.opt)])\n",
    "        if self.opt.device.type == 'cuda':\n",
    "            print('cuda memory allocated:', torch.cuda.memory_allocated(opt.device.index))\n",
    "        print(self.info)\n",
    "    \n",
    "    def _reset_records(self):\n",
    "        self.records = {\n",
    "            'best_epoch': 0,\n",
    "            'best_dice': 0,\n",
    "            'train_loss': list(),\n",
    "            'val_loss': list(),\n",
    "            'val_dice': list(),\n",
    "            'checkpoints': list()\n",
    "        }\n",
    "    \n",
    "    def _update_records(self, epoch, train_loss, val_loss, val_dice):\n",
    "        if val_dice > self.records['best_dice']:\n",
    "            path = './state_dict/{:s}_dice{:.4f}_temp{:s}.pt'.format(self.opt.model_name, val_dice, str(time.time())[-6:])\n",
    "            if self.opt.multi_gpu == 'on':\n",
    "                torch.save(self.model.module.state_dict(), path)\n",
    "            else:\n",
    "                torch.save(self.model.state_dict(), path)\n",
    "            self.records['best_epoch'] = epoch\n",
    "            self.records['best_dice'] = val_dice\n",
    "            self.records['checkpoints'].append(path)\n",
    "        self.records['train_loss'].append(train_loss)\n",
    "        self.records['val_loss'].append(val_loss)\n",
    "        self.records['val_dice'].append(val_dice)\n",
    "    \n",
    "    def _draw_records(self):\n",
    "        timestamp = str(int(time.time()))\n",
    "        print('best epoch: {:d}'.format(self.records['best_epoch']))\n",
    "        print('best train loss: {:.4f}, best val loss: {:.4f}'.format(min(self.records['train_loss']), min(self.records['val_loss'])))\n",
    "        print('best val dice {:.4f}'.format(self.records['best_dice']))\n",
    "        os.rename(self.records['checkpoints'][-1], './state_dict/{:s}_dice{:.4f}_save{:s}.pt'.format(self.opt.model_name, self.records['best_dice'], timestamp))\n",
    "        for path in self.records['checkpoints'][0:-1]:\n",
    "            os.remove(path)\n",
    "        # Draw figures\n",
    "        plt.figure()\n",
    "        trainloss, = plt.plot(self.records['train_loss'])\n",
    "        valloss, = plt.plot(self.records['val_loss'])\n",
    "        plt.legend([trainloss, valloss], ['train', 'val'], loc='upper right')\n",
    "        plt.title('{:s} loss curve'.format(timestamp))\n",
    "        plt.savefig('./figs/{:s}_loss.png'.format(timestamp), format='png', transparent=True, dpi=300)\n",
    "        plt.figure()\n",
    "        valdice, = plt.plot(self.records['val_dice'])\n",
    "        plt.title('{:s} dice curve'.format(timestamp))\n",
    "        plt.savefig('./figs/{:s}_dice.png'.format(timestamp), format='png', transparent=True, dpi=300)\n",
    "        # Save report\n",
    "        report = '\\t'.join(['val_dice', 'train_loss', 'val_loss', 'best_epoch', 'timestamp'])\n",
    "        report += \"\\n{:.4f}\\t{:.4f}\\t{:.4f}\\t{:d}\\t{:s}\\n{:s}\".format(self.records['best_dice'], min(self.records['train_loss']), min(self.records['val_loss']), self.records['best_epoch'], timestamp, self.info)\n",
    "        with open('./logs/{:s}_log.txt'.format(timestamp), 'w') as f:\n",
    "            f.write(report)\n",
    "        print('report saved:', './logs/{:s}_log.txt'.format(timestamp))\n",
    "    \n",
    "    def _train(self, train_dataloader, criterion, optimizer):\n",
    "        self.model.train()\n",
    "        train_loss, n_total, n_batch = 0, 0, len(train_dataloader)\n",
    "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "            inputs, target = sample_batched[0].to(self.opt.device), sample_batched[1].to(self.opt.device)\n",
    "            predict = self.model(inputs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(predict, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * len(sample_batched)\n",
    "            n_total += len(sample_batched)\n",
    "            \n",
    "            ratio = int((i_batch+1)*50/n_batch)\n",
    "            sys.stdout.write(\"\\r[\"+\">\"*ratio+\" \"*(50-ratio)+\"] {}/{} {:.2f}%\".format(i_batch+1, n_batch, (i_batch+1)*100/n_batch))\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "        return train_loss / n_total\n",
    "    \n",
    "    def _evaluation(self, val_dataloader, criterion):\n",
    "        self.model.eval()\n",
    "        val_loss, val_dice, n_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for sample_batched in val_dataloader:\n",
    "                inputs, target = sample_batched[0].to(self.opt.device), sample_batched[1].to(self.opt.device)\n",
    "                predict = self.model(inputs)\n",
    "                loss = criterion(predict, target)\n",
    "                dice = dice_coeff(predict, target)\n",
    "                val_loss += loss.item() * len(sample_batched)\n",
    "                val_dice += dice.item() * len(sample_batched)\n",
    "                n_total += len(sample_batched)\n",
    "        return val_loss / n_total, val_dice / n_total\n",
    "    \n",
    "    def run(self):\n",
    "        _params = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        optimizer = torch.optim.Adam(_params, lr=self.opt.lr, weight_decay=self.opt.l2reg)\n",
    "        criterion = BCELoss2d()\n",
    "        train_dataloader = DataLoader(dataset=self.trainset, batch_size=self.opt.batch_size, shuffle=True)\n",
    "        val_dataloader = DataLoader(dataset=self.valset, batch_size=self.opt.batch_size, shuffle=False)\n",
    "        self._reset_records()\n",
    "        for epoch in range(self.opt.num_epoch):\n",
    "            train_loss = self._train(train_dataloader, criterion, optimizer)\n",
    "            val_loss, val_dice = self._evaluation(val_dataloader, criterion)\n",
    "            self._update_records(epoch, train_loss, val_loss, val_dice)\n",
    "            print('{:d}/{:d} > train loss: {:.4f}, val loss: {:.4f}, val dice: {:.4f}'.format(epoch+1, self.opt.num_epoch, train_loss, val_loss, val_dice))\n",
    "        self._draw_records()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    optimizers = {\n",
    "        'adadelta': torch.optim.Adadelta, \n",
    "        'adagrad': torch.optim.Adagrad,    \n",
    "        'adam': torch.optim.Adam,       \n",
    "        'adamax': torch.optim.Adamax,   \n",
    "        'asgd': torch.optim.ASGD,         \n",
    "        'rmsprop': torch.optim.RMSprop,   \n",
    "        'sgd': torch.optim.SGD,           \n",
    "    }  \n",
    "    \n",
    "    model_name = 'unet'\n",
    "    optimizer = optimizers['adam']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    multi_gpu = 'off'\n",
    "    \n",
    "    impaths = {\n",
    "        'train': os.path.join('.', 'shoe_dataset', 'train'),\n",
    "        'val': os.path.join('.', 'shoe_dataset', 'val'),\n",
    "        'test': os.path.join('.', 'shoe_dataset', 'test'),\n",
    "        'btrain': os.path.join('.', 'shoe_dataset', 'bg', 'train'),\n",
    "        'bval': os.path.join('.', 'shoe_dataset', 'bg', 'val')\n",
    "    }\n",
    "    '''\n",
    "    # Hyperparameters\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--impath', default='shoe_dataset', type=str)\n",
    "    parser.add_argument('--imsize', default=256, type=int)\n",
    "    parser.add_argument('--aug_prob', default=0.5, type=float)\n",
    "\n",
    "    parser.add_argument('--batch_size', default=16, type=int)\n",
    "    parser.add_argument('--num_epoch', default=100, type=int)\n",
    "    parser.add_argument('--optimizer', default='adam', type=str)\n",
    "    parser.add_argument('--lr', default=1e-3, type=float)\n",
    "    parser.add_argument('--l2reg', default=1e-5, type=float)\n",
    "    parser.add_argument('--use_bilinear', default=False, type=float)\n",
    "\n",
    "    parser.add_argument('--inference', default=False, type=bool)\n",
    "    parser.add_argument('--use_crf', default=False, type=bool)\n",
    "    parser.add_argument('--checkpoint', default=None, type=str)\n",
    "    \n",
    "    parser.add_argument('--backend', default=False, type=bool)\n",
    "    parser.add_argument('--prefetch', default=False, type=bool)\n",
    "    parser.add_argument('--device', default=None, type=str, help='cpu, cuda')\n",
    "    parser.add_argument('--multi_gpu', default=None, type=str, help='on, off')\n",
    "    opt = parser.parse_args()'''\n",
    "    \n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=False)\n",
    "    model.load_state_dict(torch.load('./state_dict/unet_dice0.9730.pt', map_location='cpu'))\n",
    "    optimizer = optimizers['adam']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for folder in ['figs', 'logs', 'state_dict', 'predicts']:\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "                 \n",
    "    ## inference        \n",
    "    testset = TestImageDataset(fdir='shoe_dataset/test/', imsize=256)\n",
    "    test_dataloader = DataLoader(dataset=testset, batch_size=1, shuffle=False)\n",
    "    n_batch = len(test_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "            index, inputs = sample_batched[0], sample_batched[1].to('cpu')\n",
    "            predict = model(inputs)\n",
    "            testset.save_img(index.item(), predict, False)\n",
    "            ratio = int((i_batch+1)*50/n_batch)\n",
    "            sys.stdout.write(\"\\r[\"+\">\"*ratio+\" \"*(50-ratio)+\"] {}/{} {:.2f}%\".format(i_batch+1, n_batch, (i_batch+1)*100/n_batch))\n",
    "            sys.stdout.flush()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
