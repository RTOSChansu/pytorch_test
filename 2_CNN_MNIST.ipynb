{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN을 이용한 MNIST Dataset 학습 및 테스트 실습  \n",
    "  \n",
    "  \n",
    "이번 시간에는 MNIST Dataset을 간단한 Convolutional Neural Network를 이용하여 학습시키고 훈련된 모델을 이용하여 0~9까지의 숫자를 Classification하는 실습을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 필요한 라이브러리 임포트\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST 데이터 로드**  \n",
    "저번 시간에 이미 다운로드를 했기 때문에, 다운로드 옵션을 False로 변경하고 데이터 로더를 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터로드에 사용할 서브 프로세스 수\n",
    "num_workers = 0\n",
    "# 배치당 로드할 샘플 수\n",
    "batch_size = 20\n",
    "\n",
    "# 데이터를 Float Tensor형으로 변환합니다.\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# 학습 및 테스트 데이터 로드\n",
    "train_data = dsets.MNIST(root='data', train=True, download=False, transform=transform)\n",
    "test_data = dsets.MNIST(root='data', train=False, download=False, transform=transform)\n",
    "\n",
    "# 학습 및 테스트 데이터 로더 준비\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**간단한 CNN 설계하기**  \n",
    "저번 시간에 이미 MNIST 데이터를 시각화 해보고 어떠한 데이터셋인지 인지하였기에 이번 시간에 그 과정은 생략하고, CNN 구조를 설계해보도록 하겠습니다.  \n",
    "  \n",
    "2개의 Convolution layer와 2개의 Pooling Layer, 3개의 Fully-connected layer를 가진 간단한 CNN을 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ## nn.Conv2d(입력 채널 수, 출력 채널 수, 커널 크기, 스트라이드)\n",
    "        conv1 = nn.Conv2d(1, 6, 5, 1) # 출력 크기 = 24*24, 채널 수 = 6\n",
    "        ## nn.MaxPool2d(커널 크기 및 스트라이드)\n",
    "        pool1 = nn.MaxPool2d(2) # 출력 크기 = 12*12\n",
    "        conv2 = nn.Conv2d(6, 16, 5, 1) # 출력 크기 = 8*8, 채널 수 = 16\n",
    "        pool2 = nn.MaxPool2d(2) # 출력 크기 = 4*4\n",
    "        \n",
    "        self.conv_module = nn.Sequential(\n",
    "            conv1,\n",
    "            nn.ReLU(),\n",
    "            pool1,\n",
    "            conv2,\n",
    "            nn.ReLU(),\n",
    "            pool2\n",
    "        )\n",
    "        ## 채널 수 = 16, 출력 크기 = 4*4\n",
    "        self.fc1 = nn.Linear(16*4*4, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_module(x)\n",
    "        dim = 1\n",
    "        for d in x.size()[1:]: #FC Layer의 입력 크기를 구한다\n",
    "            dim = dim * d\n",
    "        x = x.view(-1, dim)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss 함수 및 Optimizer 지정하기**\n",
    "이번에는 Loss 함수는 CrossEntropyLoss를 사용하고, Optimizer는 Adam을 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN 학습하기**  \n",
    "위에서 설계한 CNN을 학습시켜 봅시다.\n",
    "그래프를 통하여 Loss의 변화를 파악 하여 학습이 올바르게 이루어지고 있는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "n_epochs = 20 # 학습 epoch 지정\n",
    "liveloss = PlotLosses()\n",
    "model.train() \n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    logs = {}\n",
    "    train_loss = 0.0\n",
    "    ###################\n",
    "    #    모델 학습    #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # 모든 optimizer 변수와 gradients를 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 정방향 학습 : 입력을 모델로 전달하여 예측된 출력 계산\n",
    "        output = model(data)\n",
    "        # Loss 계산\n",
    "        loss = criterion(output, target)\n",
    "        # 역전파 : 모델의 매개변수를 고려하여 loss의 gradients를 계산\n",
    "        loss.backward()\n",
    "        # 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        # 훈련 Loss 업데이트\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "        visualize_loss = train_loss/len(train_loader.dataset)\n",
    "        logs['train_loss'] = visualize_loss\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        visualize_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련된 모델 테스트 해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data, target in test_loader:\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트 결과를 시각화 하기**  \n",
    "각 숫자당 모델이 예측한 값과 실제 값을 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "output = model(images)\n",
    "_, preds = torch.max(output, 1)\n",
    "images = images.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
